# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nCW3_7MnQBOWPrQli1-ISaXhf7CM0PyA
"""

!gdown --id 1dGEhcc3hjtZKMkojdLxdSGYo2Nk4UJxF

!mkdir -p EYASE

# Extract the .rar file into the EYASE folder
!unrar x EYASE.rar EYASE/

import numpy as np
import pandas as pd
import os
import librosa
import librosa.display
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
import seaborn as sn
from IPython.display import Audio, Image

# Constants and Configuration
EMOTIONS = {0: 'ang', 1: 'hap', 2: 'neu', 3: 'sad'}
DATA_PATH = 'EYASE/EYASE'
SAMPLE_RATE = 48000
EPOCHS = 100
BATCH_SIZE = 32
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
SAVE_PATH = os.path.join(os.getcwd(), 'models')
os.makedirs('models', exist_ok=True)

# 1. Data Loading Functions
def load_dataset():
    """Load and organize the EYASE dataset."""
    file_names = []
    file_emotion = []
    file_gender = []
    data = []

    for gender_folder in os.listdir(DATA_PATH):
        gender = "female" if gender_folder.startswith("Female") else "male"
        for file in os.listdir(os.path.join(DATA_PATH, gender_folder)):
            file_path = os.path.join(DATA_PATH, gender_folder, file)
            if file.endswith(".wav"):
                emotion = file.split("_")[1].split()[0]
                # Mapping emotion to encoded number
                emotion_encoded = list(EMOTIONS.keys())[list(EMOTIONS.values()).index(emotion)]
                name_parts = file.split("_")
                name = f"{name_parts[0]}_{name_parts[-1].split()[0]}.wav"
                file_emotion.append(emotion_encoded)
                file_names.append(name)
                file_gender.append(gender)
                data.append({
                    "Name": name,
                    "Emotion": emotion_encoded,
                    "Gender": gender,
                    "Path": file_path
                })

    Data = pd.DataFrame(data)
    print(f"Number of files is {len(data)}")
    return Data

# 2. Audio Processing Functions
def get_mel_spectrogram(audio, sample_rate):
    """Generate Mel spectrogram from audio signal."""
    mel_spec = librosa.feature.melspectrogram(
        y=audio,
        sr=sample_rate,
        n_fft=1024,
        win_length=512,
        window='hamming',
        hop_length=256,
        n_mels=128,
        fmax=sample_rate/2
    )
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    return mel_spec_db

def add_awgn(signal, num_bits=16, augmented_num=2, snr_low=15, snr_high=30):
    """Add Additive White Gaussian Noise to signal for data augmentation."""
    signal_len = len(signal)
    # Generate White Gaussian noise
    noise = np.random.normal(size=(augmented_num, signal_len))

    # Normalize signal and noise
    norm_constant = 2.0 ** (num_bits - 1)
    signal_norm = signal / norm_constant
    noise_norm = noise / norm_constant

    # Compute signal and noise power
    s_power = np.sum(signal_norm ** 2) / signal_len
    n_power = np.sum(noise_norm ** 2, axis=1) / signal_len

    # Random SNR: Uniform [15, 30] in dB
    target_snr = np.random.randint(snr_low, snr_high)

    # Compute K (covariance matrix) for each noise
    K = np.sqrt((s_power / n_power) * 10 ** (- target_snr / 10))
    K = np.ones((signal_len, augmented_num)) * K

    # Generate noisy signal
    return signal + K.T * noise

def process_audio_files(data_df):
    """Process all audio files and generate mel spectrograms."""
    mel_spectrograms = []
    signals = []

    for i, file_path in enumerate(data_df.Path):
        audio, sample_rate = librosa.load(
            file_path,
            duration=3,
            offset=0.5,
            sr=SAMPLE_RATE
        )
        signal = np.zeros((int(SAMPLE_RATE * 3,)))
        signal[:len(audio)] = audio
        signals.append(signal)

        mel_spectrogram = get_mel_spectrogram(signal, sample_rate=SAMPLE_RATE)
        mel_spectrograms.append(mel_spectrogram)
        print(f"\r Processed {i}/{len(data_df)} files", end='')

    print()
    return signals, mel_spectrograms

def augment_data(signals, mel_spectrograms, data_df):
    """Augment data with noise."""
    for i, signal in enumerate(signals):
        augmented_signals = add_awgn(signal)
        for j in range(augmented_signals.shape[0]):
            mel_spectrogram = get_mel_spectrogram(
                augmented_signals[j, :],
                sample_rate=SAMPLE_RATE
            )
            mel_spectrograms.append(mel_spectrogram)
            data_df = pd.concat([data_df, data_df.iloc[i:i+1]], ignore_index=True)
        print(f"\r Processed {i}/{len(signals)} files", end='')

    print()
    return mel_spectrograms, data_df

# 3. Model Architecture - CNN Only
class CNNModel(nn.Module):
    def __init__(self, num_emotions):
        super().__init__()
        # CNN block with additional layers to compensate for LSTM removal
        self.conv2Dblock = nn.Sequential(
            # 1. conv block
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Dropout(p=0.3),

            # 2. conv block
            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=4, stride=4),
            nn.Dropout(p=0.3),

            # 3. conv block
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=4, stride=4),
            nn.Dropout(p=0.3),

            # 4. conv block
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=4, stride=4),
            nn.Dropout(p=0.3),

            # 5. Additional conv block to add depth
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1)),  # Global average pooling
            nn.Dropout(p=0.4)
        )

        # Linear softmax layer
        self.out_linear = nn.Linear(256, num_emotions)
        self.dropout_linear = nn.Dropout(p=0.3)
        self.out_softmax = nn.Softmax(dim=1)

    def print_layer_shapes(self):
        """Print layer shapes and parameters for debugging"""
        print("\nCNN Model Layer Configuration:")
        print("-" * 50)
        print("Input shape expected: (batch_size, 1, 128, varies)")
        print("\nConvolutional Layers:")

        # Print details for each CNN block
        blocks = [
            ("Block 1", [0, 1, 2, 3, 4], "1→16 channels, 3x3 kernel, MaxPool(2,2)"),
            ("Block 2", [5, 6, 7, 8, 9], "16→32 channels, 3x3 kernel, MaxPool(4,4)"),
            ("Block 3", [10, 11, 12, 13, 14], "32→64 channels, 3x3 kernel, MaxPool(4,4)"),
            ("Block 4", [15, 16, 17, 18, 19], "64→128 channels, 3x3 kernel, MaxPool(4,4)"),
            ("Block 5", [20, 21, 22, 23, 24], "128→256 channels, 3x3 kernel, AdaptiveAvgPool(1,1)")
        ]

        for name, indices, desc in blocks:
            print(f"{name}: {desc}")
            for i in indices:
                layer = self.conv2Dblock[i]
                params = sum(p.numel() for p in layer.parameters() if p.requires_grad)
                print(f"  {layer.__class__.__name__}: {params:,} parameters")

        # Print FC layer details
        print("\nClassification Layers:")
        print(f"Linear: 256 → {self.out_linear.out_features}, {sum(p.numel() for p in self.out_linear.parameters()):,} parameters")
        print(f"Dropout: p={self.dropout_linear.p}")
        print(f"Softmax: dim={1}")

        # Total parameters
        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"\nTotal trainable parameters: {total_params:,}")

    def forward(self, x):
        # Process through all CNN blocks
        x = self.conv2Dblock(x)

        # Flatten for fully connected layer
        conv_embedding = torch.flatten(x, start_dim=1)

        # Classification head
        output_logits = self.out_linear(conv_embedding)
        output_logits = self.dropout_linear(output_logits)
        output_softmax = self.out_softmax(output_logits)

        return output_logits, output_softmax

# 4. Training Functions
def loss_fnc(predictions, targets):
    """Loss function for model training."""
    return nn.CrossEntropyLoss()(input=predictions, target=targets)

def make_train_step(model, loss_fnc, optimizer):
    """Create training step function."""
    def train_step(X, Y):
        # set model to train mode
        model.train()

        # forward pass
        output_logits, output_softmax = model(X)
        predictions = torch.argmax(output_softmax, dim=1)
        accuracy = torch.sum(Y == predictions) / float(len(Y))

        # compute loss
        loss = loss_fnc(output_logits, Y)

        # compute gradients
        loss.backward()

        # update parameters and zero gradients
        optimizer.step()
        optimizer.zero_grad()

        return loss.item(), accuracy * 100

    return train_step

def make_validate_fnc(model, loss_fnc):
    """Create validation function."""
    def validate(X, Y):
        with torch.no_grad():
            model.eval()
            output_logits, output_softmax = model(X)
            predictions = torch.argmax(output_softmax, dim=1)
            accuracy = torch.sum(Y == predictions) / float(len(Y))
            loss = loss_fnc(output_logits, Y)

            return loss.item(), accuracy * 100, predictions

    return validate

# 5. Data Preparation Functions
def prepare_data(X, Y, test_size=0.1, val_size=0.1):
    """Split data into train, validation, and test sets."""
    X_train, X_val, X_test = [], [], []
    Y_train, Y_val, Y_test = [], [], []

    for emotion in range(len(EMOTIONS)):
        # Find indices where Y equals the current emotion
        emotion_ind = np.where(Y == emotion)[0]
        emotion_ind = np.random.permutation(emotion_ind)
        m = len(emotion_ind)

        ind_train = emotion_ind[:int((1 - test_size - val_size) * m)]
        ind_val = emotion_ind[int((1 - test_size - val_size) * m):int((1 - test_size) * m)]
        ind_test = emotion_ind[int((1 - test_size) * m):]

        X_train.append(X[ind_train, :, :, :])
        Y_train.append(np.array([emotion] * len(ind_train), dtype=np.int32))

        X_val.append(X[ind_val, :, :, :])
        Y_val.append(np.array([emotion] * len(ind_val), dtype=np.int32))

        X_test.append(X[ind_test, :, :, :])
        Y_test.append(np.array([emotion] * len(ind_test), dtype=np.int32))

    X_train = np.concatenate(X_train, 0)
    X_val = np.concatenate(X_val, 0)
    X_test = np.concatenate(X_test, 0)

    Y_train = np.concatenate(Y_train, 0)
    Y_val = np.concatenate(Y_val, 0)
    Y_test = np.concatenate(Y_test, 0)

    # For tracking indices
    train_ind = np.concatenate([np.where(Y == emotion)[0][:int((1 - test_size - val_size) * len(np.where(Y == emotion)[0]))]
                               for emotion in range(len(EMOTIONS))], 0)
    val_ind = np.concatenate([np.where(Y == emotion)[0][int((1 - test_size - val_size) * len(np.where(Y == emotion)[0])):int((1 - test_size) * len(np.where(Y == emotion)[0]))]
                             for emotion in range(len(EMOTIONS))], 0)

    return X_train, Y_train, X_val, Y_val, X_test, Y_test, train_ind, val_ind, np.concatenate([np.where(Y == emotion)[0][int((1 - test_size) * len(np.where(Y == emotion)[0])):]
                              for emotion in range(len(EMOTIONS))], 0)

def normalize_data(X_train, X_val, X_test):
    """Normalize data using StandardScaler."""
    scaler = StandardScaler()

    # Transform training data
    b, c, h, w = X_train.shape
    X_train = np.reshape(X_train, newshape=(b, -1))
    X_train = scaler.fit_transform(X_train)
    X_train = np.reshape(X_train, newshape=(b, c, h, w))

    # Transform validation data
    b, c, h, w = X_val.shape
    X_val = np.reshape(X_val, newshape=(b, -1))
    X_val = scaler.transform(X_val)
    X_val = np.reshape(X_val, newshape=(b, c, h, w))

    # Transform test data
    b, c, h, w = X_test.shape
    X_test = np.reshape(X_test, newshape=(b, -1))
    X_test = scaler.transform(X_test)
    X_test = np.reshape(X_test, newshape=(b, c, h, w))

    return X_train, X_val, X_test

# 6. Visualization Functions
def plot_emotion_distribution(data_df):
    """Plot distribution of emotions in the dataset."""
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.bar(
        x=range(4),
        height=data_df['Emotion'].value_counts()
    )
    ax.set_xticks(ticks=range(4))
    ax.set_xticklabels([EMOTIONS[i] for i in EMOTIONS], fontsize=10)
    ax.set_xlabel('Emotions')
    ax.set_ylabel('Number of examples')
    plt.show()

def plot_gender_distribution(data_df):
    """Plot gender distribution in the dataset."""
    fig = plt.figure()
    ax = fig.add_subplot(111)
    counts = data_df['Gender'].value_counts()
    ax.bar(
        x=[0, 1],
        height=counts.values
    )
    ax.set_xticks(ticks=[0, 1])
    ax.set_xticklabels(list(counts.index))
    ax.set_xlabel('Gender')
    ax.set_ylabel('Number of examples')
    plt.show()

def plot_training_history(losses, val_losses):
    """Plot training and validation loss history."""
    plt.figure()
    plt.plot(losses, 'b')
    plt.plot(val_losses, 'r')
    plt.legend(['train loss', 'val loss'])
    plt.title('Training History')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.show()

def plot_confusion_matrix(Y_test, predictions):
    """Plot confusion matrix."""
    cm = confusion_matrix(Y_test, predictions)
    names = [EMOTIONS[ind] for ind in range(len(EMOTIONS))]
    df_cm = pd.DataFrame(cm, index=names, columns=names)
    plt.figure(figsize=(10, 7))
    sn.set(font_scale=1.4)  # for label size
    sn.heatmap(df_cm, annot=True, annot_kws={"size": 16})  # font size
    plt.title('Confusion Matrix')
    plt.ylabel('True Emotion')
    plt.xlabel('Predicted Emotion')
    plt.show()

def main():
    # Step 1: Load data
    print("Step 1: Loading data...")
    data_df = load_dataset()

    # Step 2: Visualize data distribution
    print("Step 2: Visualizing data distribution...")
    plot_emotion_distribution(data_df)
    plot_gender_distribution(data_df)

    # Step 3: Process audio files
    print("Step 3: Processing audio files...")
    signals, mel_spectrograms = process_audio_files(data_df)

    # Step 4: Data augmentation
    print("Step 4: Performing data augmentation...")
    mel_spectrograms, data_df = augment_data(signals, mel_spectrograms, data_df)

    # Step 5: Prepare data for training
    print("Step 5: Preparing data for training...")
    X = np.stack(mel_spectrograms, axis=0)
    X = np.expand_dims(X, 1)
    print('Shape of data: ', X.shape)

    # Free memory
    del mel_spectrograms
    del signals

    # Step 6: Split data
    print("Step 6: Splitting data...")
    X_train, Y_train, X_val, Y_val, X_test, Y_test, train_ind, val_ind, test_ind = prepare_data(
        X, np.array(data_df.Emotion), test_size=0.1, val_size=0.1
    )

    print(f'X_train: {X_train.shape}, Y_train: {Y_train.shape}')
    print(f'X_val: {X_val.shape}, Y_val: {Y_val.shape}')
    print(f'X_test: {X_test.shape}, Y_test: {Y_test.shape}')

    # Check if all indices are unique
    unique, count = np.unique(
        np.concatenate([train_ind, test_ind, val_ind], 0),
        return_counts=True
    )
    print(f"Number of unique indexes is {sum(count == 1)}, out of {X.shape[0]}")

    # Free memory
    del X

    # Step 7: Normalize data
    print("Step 7: Normalizing data...")
    X_train, X_val, X_test = normalize_data(X_train, X_val, X_test)

    # Step 8: Initialize model
    print("Step 8: Initializing CNN-only model...")
    model = CNNModel(num_emotions=len(EMOTIONS)).to(DEVICE)
    print(f'Selected device is {DEVICE}')
    model.print_layer_shapes()

    # Step 9: Train model
    print("Step 9: Training model...")
    optimizer = torch.optim.SGD(
        model.parameters(),
        lr=0.01,
        weight_decay=1e-3,
        momentum=0.8
    )

    train_step = make_train_step(model, loss_fnc, optimizer=optimizer)
    validate = make_validate_fnc(model, loss_fnc)

    losses = []
    val_losses = []

    for epoch in range(EPOCHS):
        # Shuffle data
        ind = np.random.permutation(len(X_train))
        X_train = X_train[ind, :, :, :]
        Y_train = Y_train[ind]

        epoch_acc = 0
        epoch_loss = 0
        iters = int(len(X_train) / BATCH_SIZE)

        for i in range(iters):
            batch_start = i * BATCH_SIZE
            batch_end = min(batch_start + BATCH_SIZE, len(X_train))
            actual_batch_size = batch_end - batch_start

            X_batch = X_train[batch_start:batch_end, :, :, :]
            Y_batch = Y_train[batch_start:batch_end]

            X_tensor = torch.tensor(X_batch, device=DEVICE).float()
            Y_tensor = torch.tensor(Y_batch, dtype=torch.long, device=DEVICE)

            loss, acc = train_step(X_tensor, Y_tensor)
            epoch_acc += acc * actual_batch_size / len(X_train)
            epoch_loss += loss * actual_batch_size / len(X_train)

            print(f"\r Epoch {epoch}: iteration {i}/{iters}", end='')

        X_val_tensor = torch.tensor(X_val, device=DEVICE).float()
        Y_val_tensor = torch.tensor(Y_val, dtype=torch.long, device=DEVICE)
        val_loss, val_acc, _ = validate(X_val_tensor, Y_val_tensor)

        losses.append(epoch_loss)
        val_losses.append(val_loss)

        print()
        print(f"Epoch {epoch} --> loss: {epoch_loss:.4f}, acc: {epoch_acc:.2f}%, val_loss: {val_loss:.4f}, val_acc: {val_acc:.2f}%")

        # Save model every 50 epochs
        if epoch % 50 == 0 and epoch > 0:
            torch.save(model.state_dict(), os.path.join(SAVE_PATH, f'cnn_only_model_epoch_{epoch}.pt'))

    # Step 10: Save final model
    print("Step 10: Saving model...")
    torch.save(model.state_dict(), os.path.join(SAVE_PATH, 'cnn_only_model.pt'))
    print(f'Model is saved to {os.path.join(SAVE_PATH, "cnn_only_model.pt")}')

    # Step 11: Evaluate
    print("Step 11: Evaluating model...")
    X_test_tensor = torch.tensor(X_test, device=DEVICE).float()
    Y_test_tensor = torch.tensor(Y_test, dtype=torch.long, device=DEVICE)
    test_loss, test_acc, predictions = validate(X_test_tensor, Y_test_tensor)

    print(f'Test loss is {test_loss:.3f}')
    print(f'Test accuracy is {test_acc:.2f}%')

    # Step 12: Visualize results
    print("Step 12: Visualizing results...")
    plot_training_history(losses, val_losses)
    plot_confusion_matrix(Y_test, predictions.cpu().numpy())

    return model

if __name__ == "__main__":
    model = main()

